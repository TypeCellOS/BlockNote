export const AI_MODELS = [
  "openai.chat/o1-preview",
  "openai.chat/o1-mini",
  "openai.chat/gpt-4o",
  "openai.chat/gpt-4o-2024-05-13",
  "openai.chat/gpt-4o-2024-08-06",
  "openai.chat/gpt-4o-2024-11-20",
  "openai.chat/gpt-4o-audio-preview",
  "openai.chat/gpt-4o-audio-preview-2024-10-01",
  "openai.chat/gpt-4o-mini",
  "openai.chat/gpt-4o-mini-2024-07-18",
  "openai.chat/gpt-4-turbo",
  "openai.chat/gpt-4-turbo-2024-04-09",
  "openai.chat/gpt-4-turbo-preview",
  "openai.chat/gpt-4-0125-preview",
  "openai.chat/gpt-4-1106-preview",
  "openai.chat/gpt-4",
  "openai.chat/gpt-4-0613",
  "openai.chat/gpt-3.5-turbo-0125",
  "openai.chat/gpt-3.5-turbo",
  "openai.chat/gpt-3.5-turbo-1106",
  "groq.chat/gemma2-9b-it",
  "groq.chat/llama-3.3-70b-versatile",
  "groq.chat/llama-3.1-8b-instant",
  "groq.chat/llama-guard-3-8b",
  "groq.chat/llama3-70b-8192",
  "groq.chat/llama3-8b-8192",
  "groq.chat/mixtral-8x7b-32768",
  "groq.chat/deepseek-r1-distill-llama-70b-specdec",
  "groq.chat/deepseek-r1-distill-llama-70b",
  "groq.chat/llama-3.3-70b-specdec",
  "groq.chat/llama-3.2-1b-preview",
  "groq.chat/llama-3.2-3b-preview",
  "groq.chat/llama-3.2-11b-vision-preview",
  "groq.chat/llama-3.2-90b-vision-preview",
  "albert-etalab.chat/neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
];
