# AI Integration with server LLM execution + promptbuilder

This example shows how to setup to add AI integration while handling the LLM calls (in this case, using the Vercel AI SDK) on your server, using a custom executor.

Prompt building is done on the server as well
